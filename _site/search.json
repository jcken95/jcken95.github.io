[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About",
    "section": "",
    "text": "I’m Jack, a statistician, data scientist and educator based in the north east. Nice to meet you.\nI’m currently a senior data scientist at UKHSA. I completed all my studies at Newcastle University. I hold a PhD in Statistics (2023) and also obtained a First class MMathStat (2018).\nFrom a professional perspective, I love telling stories with data, learning about how to write production-ready software, anything remotely statsy and finding a data-driven solution to challenging problems. I’m donated a lot of my time to the Royal Statistical Society; serving and chairing the Young Statisticians Section and I’m also treasurer or the North Eastern local group.\nWhen I’m not doing massive nerd stuff I’m probably doing some type II fun. I fill my free time with cycling, running and walking the dog. The dog is called Robin and I don’t know what breed he is."
  },
  {
    "objectID": "projects/creepr.html",
    "href": "projects/creepr.html",
    "title": "creepr",
    "section": "",
    "text": "I really like {beepr}. For the uninitiated, the usage is simply\n\nbeepr::beep()\n\nand the result of this code snippet is a beep. Literally a solitary beep. Quite useful when you have a medium length bit of code and want some kind of indication when it has finished. There are a handful of additional noises that can be accessed by placing a number in the function call.\nThese noises are all fine. But that’s it, they’re just fine. They’re not shocking, jarring, chilling or creepy. Where’s the fun in that?\nTurns out, if you do a bit of digging, the {beepr} package provides you with the functionality to play any .wav file that’s on your machine. This can be done with\n\nbeepr:::play_file(\"/path/to/noise.wav\")\n\nThat got me thinking. If I could collated some creepy .wav files I could probably make a creepy version of {beepr} before Halloween. Probably became a reality and in fact, going from this stupid idea to a working package only took a couple of hours (and I’d forgotten how to make a package)."
  },
  {
    "objectID": "projects/creepr.html#the-prequel-beepr",
    "href": "projects/creepr.html#the-prequel-beepr",
    "title": "creepr",
    "section": "",
    "text": "I really like {beepr}. For the uninitiated, the usage is simply\n\nbeepr::beep()\n\nand the result of this code snippet is a beep. Literally a solitary beep. Quite useful when you have a medium length bit of code and want some kind of indication when it has finished. There are a handful of additional noises that can be accessed by placing a number in the function call.\nThese noises are all fine. But that’s it, they’re just fine. They’re not shocking, jarring, chilling or creepy. Where’s the fun in that?\nTurns out, if you do a bit of digging, the {beepr} package provides you with the functionality to play any .wav file that’s on your machine. This can be done with\n\nbeepr:::play_file(\"/path/to/noise.wav\")\n\nThat got me thinking. If I could collated some creepy .wav files I could probably make a creepy version of {beepr} before Halloween. Probably became a reality and in fact, going from this stupid idea to a working package only took a couple of hours (and I’d forgotten how to make a package)."
  },
  {
    "objectID": "projects/creepr.html#get-creeping",
    "href": "projects/creepr.html#get-creeping",
    "title": "creepr",
    "section": "Get creeping",
    "text": "Get creeping\nI’ve put the package on github, thus you can install and run {creepr} in the following way\n\ndevtools::install_github(\"https://github.com/jcken95/creepr\")\ncreepr::creepr()\n\nThis will play a sound from my collated sounds at random. I’ve (to date) included a whopping 8 creepy sounds: “creature”, “eerie”, “intense”, “laugh”, “piano”, “piano2”, “ringing” and “strings”.\nA feature of this package is that, even if you close R whilst the sound is playing, the sound will not terminate with R. If you play a sound, then you’re committed to it. It’s like tops 15 seconds.\nHappy creeping!"
  },
  {
    "objectID": "projects/code_review.html",
    "href": "projects/code_review.html",
    "title": "Code review for statisticians, data scientists & modellers",
    "section": "",
    "text": "I work as a data scientist alongside people who typically have academic backgrounds in statistics, public health, mathematical biology or mathematical ecology. Some of us have job titles relating to data science, other to mathematical and statistical modelling. None of us are software developers trade.\nHowever, we’re writing software all day. We’re writing mathematical/statistical models, creating data-driven products and doing data engineering. We quality assure all of this work via code review.\nThe honest answer to Who is this for? is that this is for me. It’s for a previous version of myself who knew the mechanics of reviewing code, but could have exercised a bit more nuance.\nThat being said, I think anyone working in some kind of modelling or analytical role, whose main output is some sort of mathematical or statistical analysis, but implements their processes via code could find this useful. I’ll call these people “analysts”.\nIt doesn’t really matter what programming language you use, or whether you’re storing your code on GitHub, GitLab, Bitbucket or whatever else. However this will be biased towards R and GitHub because that’s what I use. The concepts are important here, not the precise toolkit.\nIf you’re here, I’m going to assume you know roughly what a code review is, but it doesn’t hurt to have a quick refresher.\nCode review is a form of peer review. Let’s suppose you’ve written some code, made a pull request and then assigned a reviewer. The reviewer goes through your changes and looks for potential issues with the code, suggests improvements, and maybe says one or two nice things about the thing you’ve been grinding away at."
  },
  {
    "objectID": "projects/code_review.html#who-is-this-for",
    "href": "projects/code_review.html#who-is-this-for",
    "title": "Code review for statisticians, data scientists & modellers",
    "section": "",
    "text": "I work as a data scientist alongside people who typically have academic backgrounds in statistics, public health, mathematical biology or mathematical ecology. Some of us have job titles relating to data science, other to mathematical and statistical modelling. None of us are software developers trade.\nHowever, we’re writing software all day. We’re writing mathematical/statistical models, creating data-driven products and doing data engineering. We quality assure all of this work via code review.\nThe honest answer to Who is this for? is that this is for me. It’s for a previous version of myself who knew the mechanics of reviewing code, but could have exercised a bit more nuance.\nThat being said, I think anyone working in some kind of modelling or analytical role, whose main output is some sort of mathematical or statistical analysis, but implements their processes via code could find this useful. I’ll call these people “analysts”.\nIt doesn’t really matter what programming language you use, or whether you’re storing your code on GitHub, GitLab, Bitbucket or whatever else. However this will be biased towards R and GitHub because that’s what I use. The concepts are important here, not the precise toolkit.\nIf you’re here, I’m going to assume you know roughly what a code review is, but it doesn’t hurt to have a quick refresher.\nCode review is a form of peer review. Let’s suppose you’ve written some code, made a pull request and then assigned a reviewer. The reviewer goes through your changes and looks for potential issues with the code, suggests improvements, and maybe says one or two nice things about the thing you’ve been grinding away at."
  },
  {
    "objectID": "projects/code_review.html#what-is-a-reviewer-looking-for",
    "href": "projects/code_review.html#what-is-a-reviewer-looking-for",
    "title": "Code review for statisticians, data scientists & modellers",
    "section": "What is a reviewer looking for?",
    "text": "What is a reviewer looking for?\nWhen reviewing code, it’s a good idea to follow a mental checklist. I find the following works well for me and the team I’m part of:\n\nDoes the code actually run?\nCan I tell what this code should do?\nDoes the code do what it should do?\nDoes the code have clear, maintainable structure? I think Chapter 3 of Best Coding Practices for R is a good guide.\nIs the code difficult to read, overly complex or full of repetition?\nIs it clear how to use or run the code?\nDoes the code have a consistent style with evocative function and variable names?\nAre there any merge conflicts?\n\nThere’s also a second What here: what does the reviewer do during code review?\n\nAsks questions to help the reviewer understand the code.\nThis is inherently tied to the rest of code review, but I think a good way to review code is via questions. More on this later.\nAsk the code author about why they’ve implemented their methods in a certain way, ask them if they think there are better ways to do things, ask them to clarify chunks of code with unclear meaning, output or purpose and ask if their implementations are robust to future changes.\n\n\nIdentifies (potential) problems in the code:\nAs a reviewer, you need to figure out if the code meets some absolute minimum requirements. To do this, you’re going to look for\n\nDoes the code do what it should do?\nBugs (or potential future bugs).\nIncorrect mathematics/statistics.\nHave we accidentally pushed secure or sensitive information?\n\nAnything which is buggy, incorrect or insecure really shouldn’t be merged into main.\n\n\nSuggests ways to improve the code:\nYou should not just be looking for things that are wrong with the code, but also ways to improve the health of the code and your models:\n\nSuggest refactors/changes to improve clarity of code or documentation, reproducibility and/or performance.\nSuggest adding useful features.\nSuggest removing redundant or excessive features.\n\n\n\nProvides nit picks:\nNit picks, or just nits, are annoying (and something I do too much, sorry colleages), but they are invariably something a reviewer does.\nNits are usally small stylistic points. Examples include:\n\nWhite space.\nVariable/function names (this is arguably more than a nit!)\nPositioning of brackets, choice of assignment operator, and other fairly inconsequential suggestions.\n\nIn my team, we avoid this with {lintr}, {styler} and agreeing on code style as a team. We ensure their usage via precommit hooks; R users may be interested in {precommit}.\nAs a reviewer, try to use nits sparingly. Nits are allowed, but try to keep the number of them small. They’re not a hill to die on.\nIt can be a good idea to prefix your nit with “nit:” to make it clear that you’re just being a pedant and the code author can probably ignore you."
  },
  {
    "objectID": "projects/code_review.html#why-do-we-review-code",
    "href": "projects/code_review.html#why-do-we-review-code",
    "title": "Code review for statisticians, data scientists & modellers",
    "section": "Why do we review code?",
    "text": "Why do we review code?\nThere is a fairly obvious answer to this question: to check the code does what it should. But there are a whole host of reasons to review code.\n\nKnowledge transfer & collaboration\nAnalysts have a broad range of backgrounds and experiences. The reviewer can learn from the PR author, and by making suggestions, the author can learn from the reviewer by inspecting their code, running it, and asking questions.\nShared knowledge about the code base ensures there is not a single point of failure in the team: you really want your bus number to be bigger than one.\nBy reviewing code, the authors and reviewers are brought together to solve a problem. It can even be a good idea to bring in a reviewer before the work is complete to get the author unstuck, or just provide a little guidance.\n\n\nSquash bugs before they occur\nWe don’t want bugs in production code. Checking over the code before it’s put into production is the best way to prevent this. But bugs do occur, we’re only human.\n\n\nQuality and compliance:\nHere you’ll be checking that code is maintainable and well formatted. You’ll also want to check that the outputs meet a minimum standard, for example, does your model give vaguely sensible predictions?\nThere’s also a security aspect here: by reviewing code, we provide a guard against malice. This should never be a problem, but nasty people do have jobs, a little code review protects against this."
  },
  {
    "objectID": "projects/code_review.html#literal-code-review",
    "href": "projects/code_review.html#literal-code-review",
    "title": "Code review for statisticians, data scientists & modellers",
    "section": "Literal code review",
    "text": "Literal code review\nHere you’re going to look at the code, maybe run or interact with it, then make comments about the code via the pull request mechanisms.\nTo make a comment, click the + symbol to comment on a single line of code. Click a + and drag down to comment on multiple lines.\n\n\n\nimage\n\n\n\nYou can write a general comment or question in the text box.\nClick the little +/- symbol (it looks a bit like a page 📄) to make a direction suggestion on the code. This is useful when it’s simply easier to make the fix, than telling someone how to make the fix.\nClicking the symbol again will let you make a new suggestion on the same line(s) of code. Handy when you think there are multiple ways forward.\n\n\n\n\nimage\n\n\n\nClick Add single comment if the review is very short, informal or you’re just being nosey. Start review is better for longer or more formal reviews.\nOnce you’ve finished reviewing, click Review changes in the top right. You may want to write some feedback in the comment box. Then click one of Comment, Approve or Request changes as appropriate and then Submit Review.\nComments on code start a “conversation” which can be resolved. It is up to the reviewer to resolve conversations. I’d encourage authors to use emoji reactions or comments to track their work.\nYou can view changes incurred by a particular commit. Clicking the commit ID on the commit history (main page of the PR) will show you these changes. This is really useful in the ping-pong stage of the review to isolate changes."
  },
  {
    "objectID": "projects/code_review.html#guiding-principles-how-should-the-reviewer-behave",
    "href": "projects/code_review.html#guiding-principles-how-should-the-reviewer-behave",
    "title": "Code review for statisticians, data scientists & modellers",
    "section": "Guiding principles: how should the reviewer behave?",
    "text": "Guiding principles: how should the reviewer behave?\nHow should the reviewer’s behave? How should the team approach review?\n\nThe gist of things\n\nCode review needs to be inclusive\nSenior and junior members should be performing code review. Distributing review across the team helps improve knowledge transfer, and gives team members the opportunity to become familiar with large parts of the code base.\nThis also stops individual memebers of the team getting swamped with review. If all they do is review code, they’re gonna be stroppy and probably provide bad reviews.\n\n\n\nDo not allow deviations from the team style guide\nMy team adopted the tidyverse style guide, with some minor tweaks. It doesn’t really matter which style guide you use, just pick one that’s readable.\nAdopting a style guide avoids nits, makes code easier to understand, and because we know what to expect, it ultimately makes everyone’s life easier.\nI think it’s okay to be pragmatic about the style guide in a rapid response. If you’re regularly sticking to the style guide, you’ll be using it automatically anyway. But if there are problems, do spin up a second PR which cleans up the code as soon as you can.\nIf a violation of the style guide is a big fix, because you’re needing to quickly make changes to a rarely maintained part of the code base, a separate ticket or issue for this is okay too.\n\nBe kind when reviewing code\nSometimes code review can come across as blunt – we’re all really busy, it’s easier to write short, direct comments. Do try to avoid this, but it can be tricky. Reviewers should try their hardest not to be blunt, but authors should bear this in mind.\nYou can avoid being blunt by breaking up review sessions. Take your own patience into account, but if you’re reviewing for an hour or more, you’re probably going to start cutting corners and getting grumpy.\nIf you find yourself being blunt, grumpy or otherwise unsavoury, Owen recommends having a cup of tea before finalising your review. I think he’s right.\n\n\nFavour asking open ended questions instead of making opinionated, or strong statements\nYou can offer potential improvements or solutions which could be an improvement, without assuming that your suggestion is the best way forward.\nReviews in this style tend to ask for a clarification or be phrased such that the reviewer is missing some context or knowledge.\n\n\nTell people what they’ve done well!\nWe should really use code review to praise our team members too. I think this is something we (and definitely I) should do more often.\n\n\n\nResolving stalemates\nSometimes a reviewer and author can’t agree on what the best solution to a problem is. This can lead to very long games of GitHub ping-pong and grumpy team members. Here are possible scenarios, and the a suggested resolution.\nThese really are guiding principles rather than strict rules. Use your judgement.\n\nThe reviewer thinks that the PR is mostly good, but isn’t perfect\nFavour accepting imperfect PRs when when the PR improves the overall quality of:\n\nTeam outputs.\nThe codebase.\n\nIt’s generally a good idea to just get things that are “good enough” in main. I’d suggest creating issues/tickets to make the additional improvements.\nFor example, if you’ve got a functioning regression model, but there are potentially some missing interaction terms, I’d say get the okayish regression model in main, then investigate interaction terms as a seperate piece of work.\n\n\nThe author is overwhelmed with the number of changes\nOne way to help is for the reviewer could indicate how critical each request is (this could even be done in the first round of review):\n\nNit: very minor change\nOptional(/consider): I think this is a good idea. It’s not a strict requirement.\nFYI: I’m not expecting this now, it might even be out of scope. I do think you would find this interesting, or would find this to be a better way to tackle problems in the future.\nShould: an essential fix, unless you can provide me with a compelling reason not to do this.\n\n\n\nThe author thinks a requested change will take too long to fix, or is out of scope\nConsider how much fix will improve the overall team output/code health. I’d also encourage the author to try to make the fix anyway. If it takes more than (say) 10 minutes, spin up a new issue to resolve when you have more time.\n\n\nThe author and reviewer just can’t agree on the best way forward\nDeciding factors should be the readability and maintainability of the two competing approaches – I think this is especially true for analysts. We’re mostly writing in high-level languages which aren’t super fast.\nHowever, if there is a compelling performance increase in terms of memory or speed, where this is important, that may also be a deciding factor too.\nIt’s also worth setting up a (video) meeting about the code. Communication nuiances can get lost via a written format. Once you’ve done this, make a note of the main points/actions of the call somewhere in the pull request.\n\n\nConsider bringing in an additional reviewer\nSometimes, two people just really struggle to come to an agreement. I think in this case it’s best to just let someone else make the decision. * Both give your reasonings to the additional reviewer * The second reviewer’s decision is the one you go with\nFurther reading / references\n\nGoogle’s engineering practices\nGitlab blog: What is a code review?\nStackoverflow blog: How to Make Good Code Review Better\nTidyteam code review principles"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Here are my various contributions to society.\n\n\n\n\n\n\n\n\n\n\ncreepr\n\n\nIt’s just beepr but creepy\n\n\n\n\n\nNov 9, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nCode review for statisticians, data scientists & modellers\n\n\ntodo\n\n\n\n\n\nSep 11, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/code_review.html#literal-code-review-1",
    "href": "projects/code_review.html#literal-code-review-1",
    "title": "Code review for statisticians, data scientists & modellers",
    "section": "Literal code review",
    "text": "Literal code review\nHere you’re going to look at the code, maybe run or interact with it, then make comments about the code via the pull request mechanisms.\nTo maek a common, click the + symbol to comment on a single line of code. Click a + and drag down to comment on multiple lines.\n\n\n\nimage\n\n\n\nYou can write a general comment or question in the text box.\nClick the little +/- symbol (it looks a bit like a page 📄) to make a direction suggestion on the code. This is useful when it’s simply easier to make the fix, than telling someone how to make the fix.\nClicking the symbol again will let you make a new suggestion on the same line(s) of code. Handy when you think there are multiple ways forward.\n\n\n\n\nimage\n\n\n\nClick Add single comment if the review is very short, informal or you’re just being nosey. Start review is better for longer or more formal reviews.\nOnce you’ve finished reviewing, click Review changes in the top right. You may want to write some feedback in the comment box. Then click one of Comment, Approve or Request changes as appropriate and then Submit Review.\nComments on code start a “conversation” which can be resolved. It is up to the reviewer to resolve conversations. I’d encourage authors to use emoji reactions or comments to track their work.\nYou can view changes incurred by a particular commit. Clicking the commit ID on the commit history (main page of the PR) will show you these changes. This is really useful in the ping-pong stage of the review to isolate changes."
  },
  {
    "objectID": "projects/code_review.html#how-should-the-reviewers-approach-review",
    "href": "projects/code_review.html#how-should-the-reviewers-approach-review",
    "title": "Code review for statisticians, data scientists & modellers",
    "section": "How should the reviewers approach review?",
    "text": "How should the reviewers approach review?\nWe’re going to think here about how review code in a way which addresses concerns in a way which is as painless as possible. Those with an academic background will be familiar with Reviewer 2. Apoligies for any trauma I’ve just forced you to relive. We don’t want to be like reviewer 2, but there is more to consider.\n\nCode review needs to be inclusive\nSenior and junior members should be performing code review. Distributing review across the team helps improve knowledge transfer, and gives team members the opportunity to become familiar with large parts of the code base.\nThis also stops individual members of the team getting swamped with review. If all they do is review code, they’re gonning be stroppy and probably provide bad reviews.\n\n\nDo not allow deviations from the team style guide\nMy team adopted the tidyverse style guide, with some minor tweaks. It doesn’t really matter which style guide you use, just pick one that’s readable.\nAdopting a style guide avoids nits, makes code easier to understand, and because we know what to expect, it ultimately makes everyone’s life easier.\nI think it’s okay to be pragmatic about the style guide in a rapid response. If you’re regularly sticking to the style guide, you’ll be using it automatically anyway. But if there are problems, do spin up a second PR which cleans up the code as soon as you can.\nIf a violation of the style guide is a big fix, because you’re needing to quickly make changes to a rarely maintained part of the code base, a separate ticket or issue for this is okay too.\n\n\nBe kind when reviewing code\nSometimes code review can come across as blunt – we’re all really busy, it’s easier to write short, direct comments. Do try to avoid this, but it can be tricky. Reviewers should try their hardest not to be blunt, but authors should bear this in mind.\nYou can avoid being blunt by breaking up review sessions. Take your own patience into account, but if you’re reviewing for an hour or more, you’re probably going to start cutting corners and getting grumpy.\nIf you find yourself being blunt, grumpy or otherwise unsavoury, Owen recommends having a cup of tea before finalising your review. I think he’s right.\n\n\nFavour asking open ended questions instead of making opinionated, or strong statements\nYou can offer potential improvements or solutions which could be an improvement, without assuming that your suggestion is the best way forward.\nReviews in this style tend to ask for a clarification or be phrased such that the reviewer is missing some context or knowledge.\n\n\nTell people what they’ve done well!\nWe should really use code review to praise our team members too. I think this is something we (and definitely I) should do more often.\n\n\nResolving stalemates\nSometimes a reviewer and author can’t agree on what the best solution to a problem is. This can lead to very long games of GitHub ping-pong and grumpy team members. Here are possible scenarios, and the a suggested resolution.\nThese really are guiding principles rather than strict rules. Use your judgement.\n\nThe reviewer thinks that the PR is mostly good, but isn’t perfect\nFavour accepting imperfect PRs when when the PR improves the overall quality of:\n\nTeam outputs.\nThe codebase.\n\nIt’s generally a good idea to just get things that are “good enough” in main. I’d suggest creating issues/tickets to make the additional improvements.\nFor example, if you’ve got a functioning regression model, but there are potentially some missing interaction terms, I’d say get the okayish regression model in main, then investigate interaction terms as a seperate piece of work.\n\n\nThe author is overwhelmed with the number of changes\nOne way to help is for the reviewer could indicate how critical each request is (this could even be done in the first round of review):\n\nNit: very minor change\nOptional(/consider): I think this is a good idea. It’s not a strict requirement.\nFYI: I’m not expecting this now, it might even be out of scope. I do think you would find this interesting, or would find this to be a better way to tackle problems in the future.\nShould: an essential fix, unless you can provide me with a compelling reason not to do this.\n\n\n\nThe author thinks a requested change will take too long to fix, or is out of scope\nConsider how much fix will improve the overall team output/code health. I’d also encourage the author to try to make the fix anyway. If it takes more than (say) 10 minutes, spin up a new issue to resolve when you have more time.\n\n\nThe author and reviewer just can’t agree on the best way forward\nDeciding factors should be the readability and maintainability of the two competing approaches – I think this is especially true for analysts. We’re mostly writing in high-level languages which aren’t super fast.\nHowever, if there is a compelling performance increase in terms of memory or speed, where this is important, that may also be a deciding factor too.\nIt’s also worth setting up a (video) meeting about the code. Communication nuiances can get lost via a written format. Once you’ve done this, make a note of the main points/actions of the call somewhere in the pull request.\n\n\nConsider bringing in an additional reviewer\nSometimes, two people just really struggle to come to an agreement. I think in this case it’s best to just let someone else make the decision.\n\nBoth give your reasonings to the additional reviewer\nThe second reviewer’s decision is the one you go with\n\nFurther reading / references\n\nGoogle’s engineering practices\nGitlab blog: What is a code review?\nStackoverflow blog: How to Make Good Code Review Better\nTidyteam code review principles"
  }
]